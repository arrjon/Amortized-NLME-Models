{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6337b6a3",
   "metadata": {},
   "source": [
    "# Amortized Inference for a NLME Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb930b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pypesto import Problem, optimize, sample, visualize, profile, engine\n",
    "from pypesto.objective import Objective, AggregatedObjective, NegLogParameterPriors\n",
    "from scipy import stats\n",
    "\n",
    "from inference.helper_functions import (create_mixed_effect_model_param_names,\n",
    "                                        analyse_correlation_in_posterior,\n",
    "                                        create_fixed_params)\n",
    "from inference.inference_functions import run_population_optimization\n",
    "from inference.ploting_routines import (plot_real_vs_synthetic,\n",
    "                                        plot_real_and_estimated,\n",
    "                                        plot_normal_distributions,\n",
    "                                        visualize_pesto_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify which model to use\n",
    "model_name = ['fröhlich-simple', 'fröhlich-detailed', 'fröhlich-sde', \n",
    "              'pharmacokinetic_model', \n",
    "              'clairon_small_model'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adcc9cd",
   "metadata": {},
   "source": [
    "# Load individual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_type = ['normal', 'uniform'][0]\n",
    "if model_name == 'fröhlich-simple':\n",
    "    from models.froehlich_model_simple import FroehlichModelSimple\n",
    "    individual_model = FroehlichModelSimple(load_best=True, prior_type=prior_type)\n",
    "elif model_name == 'fröhlich-detailed':\n",
    "    from models.froehlich_model_detailed import FroehlichModelDetailed\n",
    "    individual_model = FroehlichModelDetailed(load_best=True, prior_type=prior_type)\n",
    "elif model_name == 'fröhlich-sde':\n",
    "    from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    individual_model = FroehlichModelSDE(load_best=True, prior_type=prior_type)    \n",
    "elif model_name == 'pharmacokinetic_model':\n",
    "    from models.pharmacokinetic_model import PharmacokineticModel\n",
    "    individual_model = PharmacokineticModel(load_best=True)    \n",
    "elif model_name == 'clairon_small_model':\n",
    "    from models.clairon_small_model import ClaironSmallModel\n",
    "    \n",
    "    n_measurements = [4, 40][0]\n",
    "    individual_model = ClaironSmallModel(load_best=True, prior_type=prior_type, n_measurements=n_measurements)\n",
    "else:\n",
    "    raise NotImplementedError('model not implemented')\n",
    "\n",
    "# assemble simulator and prior\n",
    "trainer = individual_model.build_trainer('../networks/' + individual_model.network_name)\n",
    "individual_model.plot_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5004f8ac29b11a4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define how many data points are used for optimization\n",
    "n_data = 50\n",
    "load_real_data = False\n",
    "# load data\n",
    "true_pop_parameters = None\n",
    "results_to_compare = None\n",
    "if 'Froehlich' in individual_model.name:\n",
    "    obs_data = individual_model.load_data(n_data=n_data, synthetic=not load_real_data, \n",
    "                                          load_egfp=True, load_d2egfp=False)  # if both are loaded, a 2d-list is returned\n",
    "    if not load_real_data:\n",
    "        true_pop_parameters = individual_model.load_synthetic_parameter(n_data=n_data)\n",
    "    \n",
    "    # load SDE data for comparison\n",
    "    #from models.froehlich_model_sde import FroehlichModelSDE\n",
    "    #model_sde = FroehlichModelSDE(load_best=True)\n",
    "    #obs_data = model_sde.load_data(n_data=n_data, synthetic=True)\n",
    "    #true_pop_parameters_sde = model_sde.load_synthetic_parameter(n_data=n_data)\n",
    "else:\n",
    "    if load_real_data:\n",
    "        obs_data = individual_model.load_data(n_data=n_data)\n",
    "    else:\n",
    "        synthetic_fixed_indices = [3]\n",
    "        obs_data, true_pop_parameters = individual_model.load_data(n_data=n_data, synthetic=True, \n",
    "                                                                   return_synthetic_params=True,\n",
    "                                                                   #synthetic_fixed_indices=synthetic_fixed_indices,\n",
    "                                                                   #seed=0\n",
    "                                                                   )\n",
    "        \n",
    "#outlier_id = [14, 71, 101, 107, 124, 171]    \n",
    "#obs_data = np.array([obs_data[i] for i in range(len(obs_data)) if i not in outlier_id])\n",
    "\n",
    "n_data = len(obs_data)  # in case less data is available\n",
    "print(len(obs_data), 'individuals')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b460a0b1044c110e"
  },
  {
   "cell_type": "markdown",
   "id": "6e26e6a9",
   "metadata": {},
   "source": [
    "# Estimating Population Parameters\n",
    "\n",
    "Now we want to use the amortizer to generate samples such that we can minimize the negative log-likelihood of the data given the population parameters of the mixed effect model:\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx \n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\log\\left( \\frac1M \\sum_j^M \\frac{p(\\phi_j \\mid \\beta,\\Psi)}{p(\\phi_j)} \\right).\n",
    "$$\n",
    "\n",
    "Remark: the objective value is not the likelihood value since the sum over $\\log p(y_i)$ is missing.\n",
    "\n",
    "\n",
    "$\\beta$ is called ```theta_population``` in the code.\n",
    "\n",
    "\n",
    "$\\log \\phi$ cell specific parameters, sampled from $\\mathcal{N}(\\beta,\\Psi)$\n",
    "$$\n",
    "    p( \\phi \\mid \\beta,\\Psi) = (2\\pi)^{-k/2}\\vert \\Psi\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1} \\exp \\left(-\\frac12 (\\log \\phi-\\beta)^T \\Psi^{-1}  (\\log \\phi-\\beta) \\right)\n",
    "$$\n",
    "\n",
    "Assumptions to start with: $\\Psi$ is a diagonal matrix, need better parameterization for other types\n",
    "\n",
    "$$\n",
    "    \\beta^*,\\Psi^* \\approx\n",
    "    \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log \\frac1M \\sum_j^M \\frac{p( \\phi_j \\mid \\beta,\\Psi)}{p( \\phi_j)} \\right) \\\\\n",
    "     =  \\underset{\\beta,\\Psi}{\\arg\\min} -\\sum_i \\left(\\log\\left(\\vert \\Psi\\vert^{-1/2} \\right) -\\log M -\n",
    "    \\log\\left(\\vert \\Sigma\\vert^{-1/2}\\right) +\\log \\sum_j^M \\exp \\left(-\\frac12 (\\log\\phi_j-\\beta)^T \\Psi^{-1}  (\\log\\phi_j-\\beta) + \\frac12 (\\log\\phi_j-\\mu)^T \\Sigma^{-1}  (\\log\\phi_j-\\mu) \\right)\\right)\n",
    "$$\n",
    "\n",
    "if the prior is $p( \\phi) = (2\\pi)^{-k/2}\\vert \\Sigma\\vert^{-1/2} \\prod_{l=1}^k \\phi_l^{-1}\\exp \\left(-\\frac12 (\\log \\phi-\\mu)^T \\Sigma^{-1}  (\\log\\phi-\\mu) \\right)$.\n",
    "\n",
    "\n",
    "For purpose of optimization we also parametrize $\\Psi$ by a log-transformation since diagonal entries must be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee0f98",
   "metadata": {},
   "source": [
    "## Define Objective Function\n",
    "\n",
    "- you have to choose the covariance format (diag or cholesky)\n",
    "- if you want to use covariates, you have to specify the covariate mapping to the parameters of the log-normal distribution\n",
    "- a covariate mapping takes in parameter samples (n_indv, n_samples, n_params), covariates (n_indv, n_covariates) and parameter vector with parameters needed to map the covariates into the other parameter from the mixed effects model and returns transformed parameter samples (n_indv, n_samples, n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cov_type = ['diag', 'cholesky'][0]\n",
    "use_covariates = False\n",
    "\n",
    "mixed_effect_params_names = create_mixed_effect_model_param_names(individual_model.param_names, \n",
    "                                                                  cov_type=cov_type)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23617593538cd87d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# build covariate mapping if needed\n",
    "covariates_bounds = None\n",
    "covariate_mapping = None\n",
    "n_covariates_params = 0\n",
    "covariates = None\n",
    "covariates_names = []\n",
    "\n",
    "if use_covariates and 'fröhlich' in model_name:\n",
    "    # experiment specific gamma\n",
    "    gamma_index = [ni for ni, name in enumerate(mixed_effect_params_names) if 'gamma' in name]\n",
    "    gamma_index_cov = [ni for ni, name in enumerate(mixed_effect_params_names[individual_model.n_params:]) if 'gamma' in name]\n",
    "    covariates_names = [name + '-d2eGFP' for name in mixed_effect_params_names if 'gamma' in name]\n",
    "    n_covariates_params = len(covariates_names)\n",
    "    covariates_bounds = np.array([[-5, 5]] * n_covariates_params)\n",
    "    \n",
    "    mixed_effect_params_names = mixed_effect_params_names + covariates_names\n",
    "    \n",
    "elif use_covariates and 'clairon' in model_name:\n",
    "    covariates_names = ['c_age', 'c_gender']\n",
    "    n_covariates_params = len(covariates_names)\n",
    "    covariates_bounds = np.array([[-1, 1], [-1, 1]])\n",
    "    \n",
    "    mixed_effect_params_names = mixed_effect_params_names + covariates_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ef4562ceda1aab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_covariates and 'fröhlich' in model_name:\n",
    "    # obs_data consists of two groups, first group is eGFP, second group is d2eGFP\n",
    "    if covariates is None:\n",
    "        assert len(obs_data) == 2, 'you should load two groups of data'\n",
    "        covariates = np.concatenate((np.zeros(len(obs_data[0])), np.ones(len(obs_data[1]))))[:, np.newaxis]\n",
    "        obs_data = np.concatenate((obs_data[0], obs_data[1]))\n",
    "        n_data = len(obs_data)\n",
    "        \n",
    "    from inference.nlme_objective import get_inverse_covariance\n",
    "    def multi_experiment_mapping(beta: np.ndarray,\n",
    "                                 psi_inverse_vector: np.ndarray,\n",
    "                                 covariates: np.ndarray,\n",
    "                                 covariates_params: np.ndarray):\n",
    "        \"\"\"individual_param_i = gamma_{eGFP} * (1-c) + gamma_{d2eGFP} * c + random_effect_{eGFP}, c in {0,1}\"\"\"        \n",
    "        # add param_of_cov*covariates to parameter gamma\n",
    "        # covariate_params[0] > 0 expected since lifetime of d2eGFP is lower than eGFP\n",
    "        beta_transformed = np.repeat(beta[np.newaxis, :], covariates.shape[0], axis=0)\n",
    "        psi_inverse_vector_transformed = np.repeat(psi_inverse_vector[np.newaxis, :], covariates.shape[0], axis=0)\n",
    "        psi_inverse_transformed = np.zeros((covariates.shape[0], beta.shape[0], beta.shape[0]))\n",
    "                   \n",
    "        # flatten since only one covariate     \n",
    "        beta_transformed[:, gamma_index[0]] = beta_transformed[:, gamma_index[0]] * (1-covariates.flatten()) + covariates_params[0] * covariates.flatten()\n",
    "        for i, c_i in enumerate(gamma_index_cov):\n",
    "            psi_inverse_vector_transformed[:, c_i] = psi_inverse_vector[c_i] * (1-covariates.flatten()) + covariates_params[1+i] * covariates.flatten()\n",
    "        \n",
    "        for s_id in range(covariates.shape[0]):\n",
    "            psi_inverse = get_inverse_covariance(psi_inverse_vector_transformed[s_id],\n",
    "                                                 covariance_format=cov_type,\n",
    "                                                 param_dim=beta.shape[0])\n",
    "            psi_inverse_transformed[s_id, :, :] = psi_inverse\n",
    "        return beta_transformed, psi_inverse_transformed\n",
    "    \n",
    "    covariate_mapping = multi_experiment_mapping"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e20e10a5c8a8d7ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyse correlations between parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ebfa71aac1a925"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_correlation_pairs = analyse_correlation_in_posterior(model=individual_model, \n",
    "                                                          mixed_effect_params_names=mixed_effect_params_names, \n",
    "                                                          obs_data=obs_data,\n",
    "                                                          threshold_corr=0.3)\n",
    "print('Parameter pairs of high correlation in individual posterior:', np.array(mixed_effect_params_names)[high_correlation_pairs])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de47356800882bb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fixed and Random Effects\n",
    "\n",
    "Decide which parameters to fix\n",
    "- a fixed effect is modeled as a random effect with variance 0 (all parameters follow a normal distribution)\n",
    "- variance of error parameters in the individual model are usually supposed to be a fixed parameter in the population model\n",
    "- correlations with these error parameters are usually fixed to 0\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49d1c49ce426eda8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'Froehlich' in individual_model.name:\n",
    "    # fix variance of error parameters and correlations with sigma if cholesky covariance is used\n",
    "    fix_names = ['var-$\\sigma$'] + [name for name in mixed_effect_params_names if '\\sigma' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "elif 'Pharmacokinetic' in individual_model.name:\n",
    "    fix_error_var = ['var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fix_error_var_val = [0] * len(fix_error_var)\n",
    "    # fix variance of fixed parameters\n",
    "    fixed_effects_var = ['var-$\\\\theta_1$', 'var-$\\\\theta_5$', 'var-$\\\\theta_7$', 'var-$\\\\theta_8$', \n",
    "                         'var-$\\\\theta_{10}$', 'var-$\\\\theta_{12}$', 'var-$\\\\theta_{13}$']\n",
    "    fixed_effects_var_val = [0] * len(fixed_effects_var)\n",
    "    # fix mean of random effect\n",
    "    random_effect_mean = ['pop-$\\eta_4$']\n",
    "    random_effect_mean_val = [0]\n",
    "    \n",
    "    # put all fixed parameters together\n",
    "    fix_names = fix_error_var + fixed_effects_var + random_effect_mean\n",
    "    fixed_values = fix_error_var_val + fixed_effects_var_val + random_effect_mean_val\n",
    "    \n",
    "    # if correlations are used, only allow the same as in the original model\n",
    "    # hence correlations with the error parameter are fixed as well\n",
    "    if cov_type == 'cholesky':\n",
    "        non_fix_corr = ['corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_6-\\\\eta_2$', \n",
    "                        'corr_$\\\\theta_4-\\\\eta_3$_$\\\\eta_4$']\n",
    "        fixed_corr = [x for x in mixed_effect_params_names if 'corr_' in x and x not in non_fix_corr]\n",
    "        fix_names += fixed_corr\n",
    "        fixed_values += [0] * len(fixed_corr)\n",
    "    \n",
    "elif 'Clairon' in individual_model.name:\n",
    "    fix_names = ['var-error_constant', 'var-error_prop'] + [name for name in mixed_effect_params_names if \n",
    "                                                            'error' in name and 'corr_' in name]\n",
    "    fixed_values = [0] * len(fix_names)\n",
    "else:\n",
    "    raise NotImplementedError('model not yet implemented')\n",
    "    \n",
    "# \"fix\" is here in the context of parameters which are not optimized\n",
    "fixed_indices, fixed_values = create_fixed_params(fix_names=fix_names, \n",
    "                                                  fixed_values=fixed_values,\n",
    "                                                  params_list=mixed_effect_params_names, \n",
    "                                                  fix_low_correlation=False,  # only applies to cholesky covariance\n",
    "                                                  high_correlation_pairs=high_correlation_pairs)\n",
    "print(mixed_effect_params_names)\n",
    "# note: inf values in fixed_values will be set to upper or lower bound respectively"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7555718ecb980b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fixed_indices, unique_indices = np.unique(np.array(fixed_indices), return_index=True)\n",
    "fixed_values = np.array(fixed_values)[unique_indices]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43b36c67c26baaa3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run Population Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61f974f1d64fa036"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a717d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pypesto_result, obj_fun_amortized, pesto_problem = run_population_optimization(\n",
    "    individual_model=individual_model,\n",
    "    data=obs_data,\n",
    "    param_names=mixed_effect_params_names,\n",
    "    cov_type=cov_type,\n",
    "    n_multi_starts=100,\n",
    "    n_samples_opt=250,\n",
    "    covariates_bounds=covariates_bounds,\n",
    "    covariates=covariates,\n",
    "    n_covariates_params=n_covariates_params,\n",
    "    covariate_mapping=covariate_mapping,\n",
    "    huber_loss=False,\n",
    "    x_fixed_indices=fixed_indices,\n",
    "    x_fixed_vals=fixed_values,\n",
    "    #file_name=f'../Experiments/results_nonmem/{model_name}_{cov_type}.hdf5',\n",
    "    verbose=True,\n",
    "    trace_record=False,\n",
    "    pesto_multi_processes=10,\n",
    "    use_result_as_start=False,\n",
    "    #result=pypesto_result\n",
    ")\n",
    "\n",
    "print(pypesto_result.optimize_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ax = visualize.waterfall(pypesto_result, scale_y='lin', size=(7, 4))\n",
    "ax.set_ylabel('Negative log-likelihood')\n",
    "#plt.savefig(f'../Plots/sde_waterfall.png', dpi=600)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "251507e06a6059e3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pypesto import visualize"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad5dd13ec719006d",
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "source": [
    "from pypesto import store\n",
    "pypesto_result = store.read_result(\n",
    "    filename=f'../Experiments/results_nonmem/{model_name}_{cov_type}.hdf5'\n",
    ")\n",
    "#obj_fun_amortized = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30e37a84e5653e8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d40875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_pesto_result(pypesto_result, use_batch_coloring=False, obj_fun_amortized=obj_fun_amortized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# show best result\n",
    "results = pypesto_result.optimize_result.x\n",
    "estimated_beta, psi_inverse, estimated_psi_vector, estimated_covariates_params = obj_fun_amortized.get_params(results[-1])\n",
    "estimated_psi = np.linalg.inv(psi_inverse)\n",
    "estimated_var = estimated_psi.diagonal()\n",
    "estimated_corr = estimated_psi[np.tril_indices(obj_fun_amortized.param_dim, k=-1)]\n",
    "\n",
    "display(pd.DataFrame(estimated_beta,\n",
    "                     index=mixed_effect_params_names[:individual_model.n_params],\n",
    "                     columns=['estimated population parameters']))\n",
    "display(pd.DataFrame(estimated_var,\n",
    "                     index=mixed_effect_params_names[individual_model.n_params:individual_model.n_params*2],\n",
    "                     columns=['estimated population parameters']))\n",
    "if cov_type == 'cholesky':\n",
    "    display(pd.DataFrame(estimated_corr,\n",
    "                         index=mixed_effect_params_names[individual_model.n_params*2:],\n",
    "                         columns=['estimated population parameters']))\n",
    "    \n",
    "display(pd.DataFrame(np.var([r for r in results], axis=0),\n",
    "                     index=pypesto_result.problem.x_names,\n",
    "                     columns=['variance of multi-start results']))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6441a2da84ce4968"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_normal_distributions(estimated_beta, estimated_psi, \n",
    "                          title='Population Parameter Distribution',\n",
    "                          lb=pypesto_result.problem.lb_full,\n",
    "                          ub=pypesto_result.problem.ub_full,\n",
    "                          param_names_plot=individual_model.log_param_names)\n",
    "\n",
    "plot_normal_distributions(individual_model.prior_mean, individual_model.prior_cov, \n",
    "                          title='Prior Parameter Distribution with Individual Posterior Samples',\n",
    "                          posterior_samples=obj_fun_amortized.param_samples,\n",
    "                          lb=pypesto_result.problem.lb_full,\n",
    "                          ub=pypesto_result.problem.ub_full,\n",
    "                          param_names_plot=individual_model.log_param_names)\n",
    "\n",
    "if true_pop_parameters is not None:\n",
    "    if true_pop_parameters.ndim == 2:\n",
    "        true_mean = np.mean(true_pop_parameters, axis=0)\n",
    "        true_cov = np.diag(np.var(true_pop_parameters, axis=0))\n",
    "    else:\n",
    "        true_mean = true_pop_parameters[:individual_model.n_params]\n",
    "        true_cov = np.diag(true_pop_parameters[individual_model.n_params:])\n",
    "    true_cov[true_cov < 0.001] = 0.001  # smaller cannot be estimated\n",
    "    \n",
    "    plot_normal_distributions(true_mean, \n",
    "                              true_cov, \n",
    "                              title='True Population Parameter Distribution',\n",
    "                              #posterior_samples=obj_fun_amortized.param_samples,\n",
    "                              lb=pypesto_result.problem.lb_full,\n",
    "                              ub=pypesto_result.problem.ub_full,\n",
    "                              param_names_plot=individual_model.log_param_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdac67b65f2d7a97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875e9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'fröhlich' in model_name:\n",
    "    plot_real_vs_synthetic(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data[:n_data//2] if n_covariates_params > 0 else obs_data,\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2 if n_covariates_params > 0 else n_data,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "    plot_real_and_estimated(estimated_mean=estimated_beta,\n",
    "                           estimated_cov=estimated_psi,\n",
    "                           data=obs_data[:n_data//2] if n_covariates_params > 0 else obs_data,\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2 if n_covariates_params > 0 else n_data,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           seed=0)\n",
    "    \n",
    "    if n_covariates_params > 0:\n",
    "        print(estimated_covariates_params)\n",
    "        estimated_beta_d2, estimated_inv_psi_d2 = covariate_mapping(estimated_beta, \n",
    "                                                                    estimated_psi_vector, \n",
    "                                                                    np.ones(1), \n",
    "                                                                    estimated_covariates_params)\n",
    "        print(estimated_beta[1], estimated_beta_d2[0, 1])\n",
    "        estimated_beta_d2 = estimated_beta_d2[-1]  # only second group, mean is the same for the whole group\n",
    "        estimated_inv_psi_d2 = estimated_inv_psi_d2[-1]\n",
    "        estimated_psi_d2 = np.linalg.inv(estimated_inv_psi_d2)\n",
    "        \n",
    "        plot_real_vs_synthetic(estimated_mean=estimated_beta_d2,\n",
    "                           estimated_cov=estimated_psi_d2,\n",
    "                           data=obs_data[n_data//2:],\n",
    "                           model_name=individual_model.name,\n",
    "                           n_trajectories=n_data//2,\n",
    "                           simulator=individual_model.simulator,\n",
    "                           ylim=(-1.,1.),\n",
    "                           seed=0)\n",
    "        plot_real_and_estimated(estimated_mean=estimated_beta_d2,\n",
    "                               estimated_cov=estimated_psi_d2,\n",
    "                               data=obs_data[n_data//2:],\n",
    "                               model_name=individual_model.name,\n",
    "                               n_trajectories=n_data//2,\n",
    "                               simulator=individual_model.simulator,\n",
    "                               seed=0)"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "for p in pypesto_result.optimize_result.x:\n",
    "    print(p[:2])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93b4f86a9571799f"
  },
  {
   "cell_type": "raw",
   "source": [
    "from models.froehlich_model_sde import batch_simulator\n",
    "#np.random.seed(0)\n",
    "test = pypesto_result.optimize_result.x[0][:individual_model.n_params].copy()\n",
    "#test2 = pypesto_result.optimize_result.x[-1][:individual_model.n_params].copy()\n",
    "#test[0] = 2\n",
    "\n",
    "test2 = test.copy()\n",
    "test2[0], test2[1] = test2[1], test2[0]\n",
    "#test[8], test[9] = test[9], test[8]\n",
    "print(np.stack([test, test2]))\n",
    "\n",
    "sim = batch_simulator(np.stack([test, test2]), with_noise=False)\n",
    "for s in sim:\n",
    "    plt.plot(np.linspace(1/3, 30, 180), s)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84e2f0d782ac34d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bayesian Sampling\n",
    "\n",
    "Since our amortized inference is very efficient, we can use it to sample from the posterior distribution of the population parameters."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1f91e6a18985d17"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# build neg log prior\n",
    "inv_var_prior_mean = -np.log(individual_model.prior_cov.diagonal())\n",
    "inv_var_prior_std = np.ones(len(inv_var_prior_mean))*5\n",
    "prior = NegLogParameterPriors(\n",
    "    [\n",
    "        {'index': pesto_problem.full_index_to_free_index(i), 'density_fun': lambda x: -stats.norm.logpdf(x, loc=individual_model.prior_mean[i], scale=np.sqrt(individual_model.prior_cov.diagonal()[i]))}\n",
    "     for i in range(individual_model.n_params) if i not in fixed_indices\n",
    "    ] + [\n",
    "        {'index': pesto_problem.full_index_to_free_index(i+individual_model.n_params), 'density_fun': lambda x: -stats.norm.logpdf(x, loc=inv_var_prior_mean[i], scale=inv_var_prior_std[i])}\n",
    "     for i in range(individual_model.n_params) if i+individual_model.n_params not in fixed_indices\n",
    "    ] + [\n",
    "        {'index': pesto_problem.full_index_to_free_index(i+individual_model.n_params*2), 'density_fun': lambda x: -stats.norm.logpdf(x, loc=0, scale=1)}\n",
    "     for i in range(len(mixed_effect_params_names)-individual_model.n_params*2) if i+individual_model.n_params*2 not in fixed_indices\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39e40274ab56ec31",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#param_samples = individual_model.draw_posterior_samples(data=obs_data, n_samples=250)\n",
    "#obj_fun_amortized.update_param_samples(param_samples=param_samples)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ba1f7f00f825da8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "bayesian_problem = Problem(\n",
    "    objective=AggregatedObjective([Objective(obj_fun_amortized), prior]),\n",
    "    lb=pesto_problem.lb_full, \n",
    "    ub=pesto_problem.ub_full, \n",
    "    x_names=pesto_problem.x_names,\n",
    "    x_scales=pesto_problem.x_scales,\n",
    "    x_fixed_indices=pesto_problem.x_fixed_indices,\n",
    "    x_fixed_vals=pesto_problem.x_fixed_vals,\n",
    "    x_priors_defs=prior,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13787490d8591879",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sampler = sample.AdaptiveMetropolisSampler()\n",
    "x0 = pesto_problem.get_reduced_vector(pypesto_result.optimize_result.x[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84d3e3335b863c5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pypesto_result = sample.sample(\n",
    "    bayesian_problem,\n",
    "    n_samples=100000,\n",
    "    sampler=sampler,\n",
    "    result=pypesto_result,\n",
    "    x0=x0,\n",
    "    #filename=f'../Experiments/results_nonmem/sampling_{model_name}_{cov_type}.hdf5',\n",
    "    overwrite=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1d674ed6b25160b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pypesto_result = store.read_result(\n",
    "    filename=f'../Experiments/results_nonmem/sampling_{model_name}_{cov_type}.hdf5'\n",
    ")\n",
    "obj_fun_amortized = None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11fa899344e4627e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sample.geweke_test(pypesto_result)\n",
    "ax = visualize.sampling_1d_marginals(pypesto_result)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46bbf802cd84f18",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# extract 95% credible intervals\n",
    "param_quantiles = np.quantile(pypesto_result.sample_result.trace_x, [0.01, 0.99], axis=1)\n",
    "param_quantiles = param_quantiles[:, 0, :]\n",
    "param_median = np.median(pypesto_result.sample_result.trace_x, axis=1).flatten()\n",
    "# compute difference from median to 95% quantile\n",
    "param_quantiles_dif = np.abs(param_median-param_quantiles)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1175ae8ef55e885",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10c2ddb01108c23",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'Pharmacokinetic' in individual_model.name:\n",
    "    # load SAEM data\n",
    "    raw_data_SAEM = pd.read_csv(f'../Experiments/results_nonmem/SAEM_ordered_population_parameters_w_corr.csv', delimiter=',',\n",
    "                               index_col=0, header=0)\n",
    "    raw_data_SAEM[['omega_V_2', 'omega_CLP', 'omega_V_3', 'omega_f_m']] = raw_data_SAEM[['omega_V_2', 'omega_CLP', 'omega_V_3', 'omega_f_m']].values **2\n",
    "    raw_data_SAEM[['ay2', 'ay2']] = np.log(raw_data_SAEM[['ay2', 'ay2']].values)\n",
    "    #likelihoods = pd.read_csv(f'../Experiments/results_nonmem/ordered_likelihoods.csv', delimiter=',',\n",
    "    #                           index_col=0, header=0)\n",
    "    df_mapping = {'pop-$\\\\theta_1$': 'k_a_pop',\n",
    "     'pop-$\\\\theta_2-\\\\eta_1$': 'V_2_pop',\n",
    "     'pop-$\\\\theta_4-\\\\eta_3$': 'CLP_pop',\n",
    "     'pop-$\\\\theta_5$': 'CLM_pop',\n",
    "     'pop-$\\\\theta_6-\\\\eta_2$': 'V_3_pop',\n",
    "     'pop-$\\\\theta_7$': 'Q_34_pop',\n",
    "     'pop-$\\\\theta_8$': 'V_4_pop',\n",
    "     'pop-$\\\\theta_{10}$': 'Q_25_pop',\n",
    "     'pop-$\\\\theta_{12}$': 'ay2', \n",
    "     'pop-$\\\\theta_{13}$': 'ay3',\n",
    "     'pop-$\\\\eta_4$': 0,\n",
    "     'var-$\\\\theta_1$': 0,\n",
    "     'var-$\\\\theta_2-\\\\eta_1$': 'omega_V_2',\n",
    "     'var-$\\\\theta_4-\\\\eta_3$': 'omega_CLP',\n",
    "     'var-$\\\\theta_5$': 0,\n",
    "     'var-$\\\\theta_6-\\\\eta_2$': 'omega_V_3',\n",
    "     'var-$\\\\theta_7$': 0,\n",
    "     'var-$\\\\theta_8$': 0,\n",
    "     'var-$\\\\theta_{10}$': 0,\n",
    "     'var-$\\\\theta_{12}$': 0,\n",
    "     'var-$\\\\theta_{13}$': 0,\n",
    "     'var-$\\\\eta_4$': 'omega_f_m',\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_2-\\\\eta_1$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_4-\\\\eta_3$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_4-\\\\eta_3$': 'corr_V_2_CLP', #'OMEGA(3,1)',                     \n",
    "     'corr_$\\\\theta_1$_$\\\\theta_5$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_5$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_5$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_6-\\\\eta_2$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_6-\\\\eta_2$': 'corr_V_3_V_2', #'OMEGA(2,1)',\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_6-\\\\eta_2$': 'corr_V_3_CLP', #'OMEGA(3,2)',\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_6-\\\\eta_2$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_{10}$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_{10}$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_{12}$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\eta_4$': 'corr_f_m_V_2', #'OMEGA(4,1)',\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\eta_4$': 'corr_f_m_CLP', #'OMEGA(4,3)',\n",
    "     'corr_$\\\\theta_5$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\eta_4$': 'corr_f_m_V_3', #'OMEGA(4,2)',\n",
    "     'corr_$\\\\theta_7$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_{10}$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_{12}$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_{13}$_$\\\\eta_4$': 0}\n",
    "    \n",
    "    # iterater over raw_data and rename columns if column name is a value\n",
    "    # if column does not exist in values of df_mapping, drop it\n",
    "    for col in raw_data_SAEM.columns:\n",
    "        if col in df_mapping.values():\n",
    "            raw_data_SAEM.rename(columns={col: list(df_mapping.keys())[list(df_mapping.values()).index(col)]}, inplace=True)\n",
    "        else:\n",
    "            raw_data_SAEM.drop(columns=[col], inplace=True)\n",
    "    #raw_data_SAEM = raw_data_SAEM.iloc[:1]\n",
    "    \n",
    "    for col in raw_data_SAEM:\n",
    "        if 'corr' in col:\n",
    "            # find which etas are in this column\n",
    "            etas = [x for x in re.findall(r'\\\\eta_\\d+', col)]\n",
    "            var = []\n",
    "            if '\\\\eta_1' in etas:\n",
    "                var.append(raw_data_SAEM['var-$\\\\theta_2-\\\\eta_1$'].values)\n",
    "            if '\\\\eta_2' in etas:\n",
    "                var.append(raw_data_SAEM['var-$\\\\theta_6-\\\\eta_2$'].values)\n",
    "            if '\\\\eta_3' in etas:\n",
    "                var.append(raw_data_SAEM['var-$\\\\theta_4-\\\\eta_3$'].values)\n",
    "            if '\\\\eta_4' in etas:\n",
    "                var.append(raw_data_SAEM['var-$\\\\eta_4$'].values)\n",
    "            raw_data_SAEM[col] = raw_data_SAEM[col].values * np.prod(np.sqrt(var), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc5253f99986fe64",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'Pharmacokinetic' in individual_model.name:    \n",
    "    # load nonmem data\n",
    "    raw_data = pd.read_csv(f'../Experiments/results_nonmem/retries_sunitinib_lognor.csv', delimiter=',',\n",
    "                               index_col=0, header=0)\n",
    "    raw_data['time'] = raw_data['subprob_est_time'] + raw_data['subprob_cov_time']\n",
    "    raw_data['time'] = np.nanmax(raw_data[['time', 'CPU-time [s]']], axis=1)\n",
    "    raw_data[['OMEGA(3,1)', 'OMEGA(3,2)', 'OMEGA(4,1)', 'OMEGA(4,2)', 'OMEGA(4,3)']] = raw_data[['OMEGA(3,1)', 'OMEGA(3,2)', 'OMEGA(4,1)', 'OMEGA(4,2)', 'OMEGA(4,3)']].values**2\n",
    "\n",
    "\n",
    "    df_mapping = {'pop-$\\\\theta_1$': '1 = K12  Absorption rate constant',\n",
    "     'pop-$\\\\theta_2-\\\\eta_1$': '2 = V2  Central volume of distribution of sunitinib',\n",
    "     'pop-$\\\\theta_4-\\\\eta_3$': '4 = CLP  Clearance of sunitinib',\n",
    "     'pop-$\\\\theta_5$': '5 = CLM  Clearance of SU12662',\n",
    "     'pop-$\\\\theta_6-\\\\eta_2$': '6 = V3  Central volume of distribution of SU12662',\n",
    "     'pop-$\\\\theta_7$': '7 = Q34  Inter-compartmental clearance of SU12662',\n",
    "     'pop-$\\\\theta_8$': '8 = V4  Peripheral volumes of distribution of SU12662',\n",
    "     'pop-$\\\\theta_{10}$': '10 = Q25  Inter-compartmental clearance of Sunitinib',\n",
    "     'pop-$\\\\theta_{12}$': '12 =  Prop. Error Suni', \n",
    "     'pop-$\\\\theta_{13}$': '13 = Prop. Error Metab',\n",
    "     'pop-$\\\\eta_4$': 0,\n",
    "     'var-$\\\\theta_1$': 0,\n",
    "     'var-$\\\\theta_2-\\\\eta_1$': '1 IIV V2',\n",
    "     'var-$\\\\theta_4-\\\\eta_3$': '3 IIV CLP',\n",
    "     'var-$\\\\theta_5$': 0,\n",
    "     'var-$\\\\theta_6-\\\\eta_2$': '2 IIV V3',\n",
    "     'var-$\\\\theta_7$': 0,\n",
    "     'var-$\\\\theta_8$': 0,\n",
    "     'var-$\\\\theta_{10}$': 0,\n",
    "     'var-$\\\\theta_{12}$': 0,\n",
    "     'var-$\\\\theta_{13}$': 0,\n",
    "     'var-$\\\\eta_4$': '4 IIV FM',\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_2-\\\\eta_1$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_4-\\\\eta_3$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_4-\\\\eta_3$': 'OMEGA(3,1)',\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_5$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_5$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_5$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_6-\\\\eta_2$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_6-\\\\eta_2$': 'OMEGA(2,1)',\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_6-\\\\eta_2$': 'OMEGA(3,2)',\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_6-\\\\eta_2$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_7$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_8$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\theta_{10}$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_{10}$_$\\\\theta_{12}$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_5$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_7$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_{10}$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_{12}$_$\\\\theta_{13}$': 0,\n",
    "     'corr_$\\\\theta_1$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_2-\\\\eta_1$_$\\\\eta_4$': 'OMEGA(4,1)',\n",
    "     'corr_$\\\\theta_4-\\\\eta_3$_$\\\\eta_4$': 'OMEGA(4,3)',\n",
    "     'corr_$\\\\theta_5$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_6-\\\\eta_2$_$\\\\eta_4$': 'OMEGA(4,2)',\n",
    "     'corr_$\\\\theta_7$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_8$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_{10}$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_{12}$_$\\\\eta_4$': 0,\n",
    "     'corr_$\\\\theta_{13}$_$\\\\eta_4$': 0,\n",
    "    'likelihood': 'ofv',\n",
    "    'computation_time': 'time'}\n",
    "    \n",
    "    # iterater over raw_data and rename columns if column name is a value\n",
    "    # if column does not exist in values of df_mapping, drop it\n",
    "    for col in raw_data.columns:\n",
    "        if col in df_mapping.values():\n",
    "            raw_data.rename(columns={col: list(df_mapping.keys())[list(df_mapping.values()).index(col)]}, inplace=True)\n",
    "        else:\n",
    "            raw_data.drop(columns=[col], inplace=True)\n",
    "            \n",
    "    for col in raw_data.columns:\n",
    "        if col[:3] == 'pop':\n",
    "            raw_data[col] = np.log(np.abs(raw_data[col]))\n",
    "        \n",
    "    # update correlations to covariances    \n",
    "    for col in raw_data:\n",
    "        if 'corr' in col:\n",
    "            # find which etas are in this column\n",
    "            etas = [x for x in re.findall(r'\\\\eta_\\d+', col)]\n",
    "            var = []\n",
    "            if '\\\\eta_1' in etas:\n",
    "                var.append(raw_data['var-$\\\\theta_2-\\\\eta_1$'].values)\n",
    "            if '\\\\eta_2' in etas:\n",
    "                var.append(raw_data['var-$\\\\theta_6-\\\\eta_2$'].values)\n",
    "            if '\\\\eta_3' in etas:\n",
    "                var.append(raw_data['var-$\\\\theta_4-\\\\eta_3$'].values)\n",
    "            if '\\\\eta_4' in etas:\n",
    "                var.append(raw_data['var-$\\\\eta_4$'].values)\n",
    "            raw_data[col] = raw_data[col].values * np.prod(np.sqrt(var), axis=0)\n",
    "            \n",
    "            \n",
    "    #old_columns = raw_data.columns.copy()\n",
    "    #for name in df_mapping.keys():\n",
    "    #    if name not in raw_data.columns:\n",
    "    #        raw_data[name] = 0\n",
    "            \n",
    "    raw_data.sort_values(by=['likelihood'], inplace=True)\n",
    "    print(raw_data.shape)\n",
    "    # drop nan\n",
    "    #raw_data.dropna(inplace=True)\n",
    "    #print(raw_data.shape)\n",
    "    \n",
    "    # make an error plot with median and one std per parameter\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "    i, j, l  = 0, 0, 0\n",
    "    plot_names = []\n",
    "    \n",
    "    results = pypesto_result.optimize_result.x\n",
    "    covs = []\n",
    "    for r in results:\n",
    "        estimated_beta, psi_inverse, estimated_psi_vector, estimated_covariates_params = obj_fun_amortized.get_params(r)\n",
    "        estimated_psi = np.linalg.inv(psi_inverse)\n",
    "        covs.append(estimated_psi)\n",
    "    \n",
    "    for name in mixed_effect_params_names:\n",
    "        if name in raw_data.columns:  # other parameters are 0 anyway\n",
    "                \n",
    "            # plot amortized parameter estimates\n",
    "            if name[:3] == 'var':\n",
    "                # make variance parameters\n",
    "                print('nonmem', raw_data[name].median())\n",
    "                print(name, np.exp(-param_quantiles_dif[:, i-l])[:, np.newaxis])\n",
    "                ax.errorbar(\n",
    "                        y=np.exp(-param_median[i]),\n",
    "                        #y=np.median(np.exp(-np.array(pypesto_result.optimize_result.x)[:, i])), \n",
    "                        x=i,\n",
    "                        #yerr=np.std(np.exp(-np.array(pypesto_result.optimize_result.x)[:, i]))*3, \n",
    "                        yerr=np.exp(-param_quantiles_dif[:, i-l])[:, np.newaxis],\n",
    "                        fmt='o', color='blue', label='amortized approach' if i == 0 else None, zorder=3)\n",
    "            elif name[:4] == 'corr':\n",
    "                if name not in non_fix_corr:\n",
    "                    continue\n",
    "                # make correlation parameters\n",
    "                # extract the correct parameters values\n",
    "                corr_values = []\n",
    "                for cov in covs:\n",
    "                    corr_values.append(cov[np.tril_indices(obj_fun_amortized.param_dim, k=-1)][j])\n",
    "                \n",
    "                ax.errorbar(y=np.median(corr_values), x=i,\n",
    "                        yerr=np.std(corr_values)*3, \n",
    "                        fmt='o', color='blue', label='amortized approach' if i == 0 else None, zorder=3)\n",
    "            else:\n",
    "                ax.errorbar(\n",
    "                        y=param_median[i],\n",
    "                        #y=np.median(np.array(pypesto_result.optimize_result.x)[:, i])\n",
    "                        x=i,\n",
    "                        #yerr=np.std(np.array(pypesto_result.optimize_result.x)[:, i])*3, \n",
    "                        yerr=param_quantiles_dif[:, i-l][:, np.newaxis],\n",
    "                        fmt='o', color='blue', label='amortized approach' if i == 0 else None, zorder=3)\n",
    "                \n",
    "            # population parameters in NONMEM\n",
    "            ax.errorbar(y=raw_data[name].median(), x=i, yerr=raw_data[name].std(), fmt='o', color='red', label='FOCEI' if i == 0 else None, zorder=2)\n",
    "                \n",
    "             # plot SAEM estimates\n",
    "            if name in raw_data_SAEM.columns:\n",
    "                if name[:3] == 'var':\n",
    "                    print('monolix', raw_data_SAEM[name].median())\n",
    "                ax.errorbar(y=raw_data_SAEM[name].median(), x=i, yerr=raw_data_SAEM[name][:10].std(), color='orange', fmt='o', label='SAEM' if i == 0 else None, zorder=1)\n",
    "                \n",
    "                \n",
    "            if name[:3] == 'pop':\n",
    "                ax.errorbar(y=individual_model.prior_mean[i], x=i, yerr=individual_model.prior_std[i]*3,  marker=None, color='green', label='individual prior' if i == 0 else None, alpha=0.5,\n",
    "                            zorder=0)\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            if name[:4] == 'corr':\n",
    "                plot_names.append('cov'+name[4:])\n",
    "            else:\n",
    "                plot_names.append(name)\n",
    "        if name[:4] == 'corr':\n",
    "            j += 1\n",
    "            \n",
    "            \n",
    "    ax.set_xticks(range(len(plot_names)))\n",
    "    ax.set_xticklabels(plot_names, rotation=90)\n",
    "    lgd = ax.legend(loc='lower center', ncol=2, bbox_to_anchor=(0.5, -1))\n",
    "    #plt.ylim(-10, 10)\n",
    "    #plt.savefig('../plots/paper/pharma_pop_parameters.pdf', format='pdf', bbox_inches='tight', # pad_inches=0.2,\n",
    "    #            \n",
    "    #            bbox_extra_artists=(lgd,))\n",
    "    plt.show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "582df324c4d8aec2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# get names which are also in nonmem\n",
    "#nonmem_names = [name for name in mixed_effect_params_names if name in raw_data.columns]\n",
    "# get best nonmem parameters\n",
    "FOCEI_params = raw_data.iloc[0]\n",
    "SAEM_params = raw_data_SAEM.iloc[0]\n",
    "\n",
    "# build mean\n",
    "FOCEI_mean = np.zeros(individual_model.n_params)\n",
    "SAEM_mean = np.zeros(individual_model.n_params)\n",
    "for i, mean in enumerate(mixed_effect_params_names[:individual_model.n_params]):\n",
    "    if mean in FOCEI_params.index:\n",
    "        FOCEI_mean[i] = FOCEI_params[mean]\n",
    "    if mean in SAEM_params.index:\n",
    "        SAEM_mean[i] = SAEM_params[mean]\n",
    "\n",
    "# build cov\n",
    "FOCEI_cov = np.diag(np.zeros(individual_model.n_params))\n",
    "SAEM_cov = np.diag(np.zeros(individual_model.n_params))\n",
    "for i, var in enumerate(mixed_effect_params_names[individual_model.n_params:individual_model.n_params*2]):\n",
    "    if var in FOCEI_params.index:\n",
    "        FOCEI_cov[i, i] = FOCEI_params[var]\n",
    "    if var in SAEM_params.index:\n",
    "        SAEM_cov[i, i] = SAEM_params[var]\n",
    "\n",
    "for i, c in enumerate(mixed_effect_params_names[individual_model.n_params*2:]):\n",
    "    if c in FOCEI_params.index:\n",
    "        FOCEI_cov[np.tril_indices(obj_fun_amortized.param_dim, k=-1)[0][i], \n",
    "                    np.tril_indices(obj_fun_amortized.param_dim, k=-1)[1][i]] = FOCEI_params[c]\n",
    "        FOCEI_cov[np.tril_indices(obj_fun_amortized.param_dim, k=-1)[1][i], \n",
    "                    np.tril_indices(obj_fun_amortized.param_dim, k=-1)[0][i]] = FOCEI_params[c]\n",
    "    if c in SAEM_params.index:\n",
    "        SAEM_cov[np.tril_indices(obj_fun_amortized.param_dim, k=-1)[0][i], \n",
    "                    np.tril_indices(obj_fun_amortized.param_dim, k=-1)[1][i]] = SAEM_params[c]\n",
    "        SAEM_cov[np.tril_indices(obj_fun_amortized.param_dim, k=-1)[1][i], \n",
    "                    np.tril_indices(obj_fun_amortized.param_dim, k=-1)[0][i]] = SAEM_params[c]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94b69a0875ee7c1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "if 'Pharmacokinetic' in individual_model.name:\n",
    "    from models.pharmacokinetic_model import convert_bf_to_observables, batch_simulator as pharma_simulator\n",
    "    estimated_beta, psi_inverse, estimated_psi_vector, estimated_covariates_params = obj_fun_amortized.get_params(results[0])\n",
    "    np.random.seed(42)\n",
    "    n_population_samples = 100\n",
    "    simulate_noise = True\n",
    "    \n",
    "    parameter_batch = np.random.multivariate_normal(estimated_beta, estimated_psi, size=n_population_samples)\n",
    "    parameter_batch_FOCEI = np.random.multivariate_normal(FOCEI_mean, FOCEI_cov, size=n_population_samples)\n",
    "    parameter_batch_SAEM = np.random.multivariate_normal(SAEM_mean, SAEM_cov, size=n_population_samples)\n",
    "    #parameter_batch_FOCEI = np.log(np.random.multivariate_normal(np.exp(FOCEI_mean), FOCEI_cov, size=n_population_samples))\n",
    "    \n",
    "    # plot individuals with samples from the population parameters\n",
    "    simulations = []\n",
    "    simulations_FOCEI = []\n",
    "    simulations_SAEM = []\n",
    "    simulations_full = []\n",
    "    simulations_FOCEI_full = []\n",
    "    simulations_SAEM_full = []\n",
    "    for patient_i in tqdm(obs_data):\n",
    "        # get patient data\n",
    "        y_i, t_measurements_i, doses_time_points_i, dos_i, wt_i = convert_bf_to_observables(patient_i)\n",
    "        t_measurement = np.linspace(0, t_measurements_i[-1]*1.1, int(t_measurements_i[-1]))\n",
    "        # get individual simulations\n",
    "        sim_i = pharma_simulator(parameter_batch, \n",
    "                                 t_measurement=t_measurement,\n",
    "                                 t_doses=doses_time_points_i, \n",
    "                                 dos=dos_i, \n",
    "                                 wt=wt_i,\n",
    "                                 with_noise=simulate_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "        simulations_full.append(sim_i) \n",
    "        sim_i = pharma_simulator(parameter_batch, \n",
    "                                 t_measurement=t_measurements_i,\n",
    "                                 t_doses=doses_time_points_i, \n",
    "                                 dos=dos_i, \n",
    "                                 wt=wt_i,\n",
    "                                 with_noise=simulate_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "        simulations.append(sim_i) \n",
    "        \n",
    "        # get FOCEI simulations\n",
    "        sim_i = pharma_simulator(parameter_batch_FOCEI, \n",
    "                                 t_measurement=t_measurement,\n",
    "                                 t_doses=doses_time_points_i, \n",
    "                                 dos=dos_i, \n",
    "                                 wt=wt_i,\n",
    "                                 with_noise=simulate_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "        simulations_FOCEI_full.append(sim_i)\n",
    "        sim_i = pharma_simulator(parameter_batch_FOCEI, \n",
    "                                 t_measurement=t_measurements_i,\n",
    "                                 t_doses=doses_time_points_i, \n",
    "                                 dos=dos_i, \n",
    "                                 wt=wt_i,\n",
    "                                 with_noise=simulate_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "        simulations_FOCEI.append(sim_i)\n",
    "        \n",
    "        # get SAEM simulations\n",
    "        sim_i = pharma_simulator(parameter_batch_SAEM, \n",
    "                                 t_measurement=t_measurement,\n",
    "                                 t_doses=doses_time_points_i, \n",
    "                                 dos=dos_i, \n",
    "                                 wt=wt_i,\n",
    "                                 with_noise=simulate_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "        simulations_SAEM_full.append(sim_i)\n",
    "        sim_i = pharma_simulator(parameter_batch_SAEM, \n",
    "                                 t_measurement=t_measurements_i,\n",
    "                                 t_doses=doses_time_points_i, \n",
    "                                 dos=dos_i, \n",
    "                                 wt=wt_i,\n",
    "                                 with_noise=simulate_noise,\n",
    "                                 convert_to_bf_batch=False)\n",
    "        simulations_SAEM.append(sim_i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef59143ae81a0195",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "real_data_a2 = []\n",
    "real_data_a3 = []\n",
    "sim_a2 = []\n",
    "sim_a3 = []\n",
    "sim_a2_FOCEI = []\n",
    "sim_a3_FOCEI = []\n",
    "sim_a2_SAEM = []\n",
    "sim_a3_SAEM = []\n",
    "\n",
    "for i, (patient_i, simulations_i, simulations_FOCEI_i, simulations_SAEM_i) in enumerate(zip(obs_data, simulations, simulations_FOCEI, simulations_SAEM)):\n",
    "    y_i, t_measurements_i, _, _, _ = convert_bf_to_observables(patient_i)\n",
    "    real_data_a2.append(y_i[:, 0])\n",
    "    real_data_a3.append(y_i[:, 1])\n",
    "    \n",
    "    sim_a2.append(np.median(simulations_i[:, :, 0], axis=0))\n",
    "    sim_a3.append(np.median(simulations_i[:, :, 1], axis=0))\n",
    "    sim_a2_FOCEI.append(np.median(simulations_FOCEI_i[:, :, 0], axis=0))\n",
    "    sim_a3_FOCEI.append(np.median(simulations_FOCEI_i[:, :, 1], axis=0))\n",
    "    sim_a2_SAEM.append(np.median(simulations_SAEM_i[:, :, 0], axis=0))\n",
    "    sim_a3_SAEM.append(np.median(simulations_SAEM_i[:, :, 1], axis=0))\n",
    "       \n",
    "real_data_a2 = np.concatenate(real_data_a2)\n",
    "real_data_a3 = np.concatenate(real_data_a3)\n",
    "sim_a2 = np.concatenate(sim_a2)\n",
    "sim_a3 = np.concatenate(sim_a3)\n",
    "sim_a2_FOCEI = np.concatenate(sim_a2_FOCEI)\n",
    "sim_a3_FOCEI = np.concatenate(sim_a3_FOCEI)\n",
    "sim_a2_SAEM = np.concatenate(sim_a2_SAEM)\n",
    "sim_a3_SAEM = np.concatenate(sim_a3_SAEM)\n",
    "\n",
    "# sort\n",
    "real_data_a2 = np.sort(real_data_a2)\n",
    "real_data_a3 = np.sort(real_data_a3)\n",
    "\n",
    "sim_a2 = np.sort(sim_a2)\n",
    "sim_a3 = np.sort(sim_a3)\n",
    "\n",
    "sim_a2_FOCEI = np.sort(sim_a2_FOCEI)\n",
    "sim_a3_FOCEI = np.sort(sim_a3_FOCEI)\n",
    "\n",
    "sim_a2_SAEM = np.sort(sim_a2_SAEM)\n",
    "sim_a3_SAEM = np.sort(sim_a3_SAEM)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f36f846c793d5b3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create Q-Q plot\n",
    "fig, ax = plt.subplots(2, 1, sharex=True, figsize=(6, 6))\n",
    "ax[0].scatter(sim_a2, real_data_a2, marker='o', color='blue', label='Amortized')\n",
    "ax[0].scatter(sim_a2_FOCEI, real_data_a2, marker='o', color='orange', label='FOCEI')\n",
    "ax[0].scatter(sim_a2_SAEM, real_data_a2, marker='o', color='green', label='SAEM')\n",
    "\n",
    "\n",
    "#plt.scatter(sim_a3, real_data_a3, color='green', edgecolors='black', alpha=0.6)\n",
    "ax[0].plot(real_data_a2, real_data_a2, color='red', linestyle='--')\n",
    "ax[0].set_title('Q-Q Plot - A2')\n",
    "ax[0].set_ylabel('Real Data')\n",
    "#ax[0].set_xlabel('Simulated')\n",
    "\n",
    "\n",
    "ax[1].scatter(sim_a3, real_data_a3, marker='o', color='blue', label='Amortized')\n",
    "ax[1].scatter(sim_a3_FOCEI, real_data_a3, marker='o', color='orange', label='FOCEI')\n",
    "ax[1].scatter(sim_a3_SAEM, real_data_a3, marker='o', color='green', label='SAEM')\n",
    "\n",
    "#plt.scatter(sim_a3, real_data_a3, color='green', edgecolors='black', alpha=0.6)\n",
    "ax[1].plot(real_data_a3, real_data_a3, color='red', linestyle='--')\n",
    "ax[1].set_title('Q-Q Plot - A3')\n",
    "ax[1].set_ylabel('Real Data')\n",
    "ax[1].set_xlabel('Simulated')\n",
    "\n",
    "for a in ax:\n",
    "    a.legend()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58fb906f24c1a51",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'small',\n",
    "                     'ytick.labelsize': 'small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,\n",
    "                     'figure.figsize': (16,9)}) #"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79bf00eb9f613d7a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed25d2bda261cb5d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'Pharmacokinetic' in individual_model.name:\n",
    "    # plot individuals with samples from the population parameters\n",
    "    fig, ax = plt.subplots(4, 3, figsize=(12, 8), sharex=True, sharey=True) #, tight_layout=True)\n",
    "    \n",
    "    # plot random individuals\n",
    "    rand_indv = [0, 17, 33] #10\n",
    "    #rand_indv = np.random.choice(range(len(obs_data)), len(ax[0]))\n",
    "    i = 0\n",
    "    for j, (patient_i, simulations_i, simulations_nonmem_i) in enumerate(zip(obs_data, simulations_full, simulations_FOCEI_full)):\n",
    "        if j not in rand_indv:\n",
    "            continue\n",
    "        \n",
    "        y_i, t_measurements_i, doses_time_points_i, _, _ = convert_bf_to_observables(patient_i)\n",
    "        t_measurement = np.linspace(0, t_measurements_i[-1]*1.1, int(t_measurements_i[-1])) / 24\n",
    "        doses_time_points_i = np.array(doses_time_points_i) / 24\n",
    "        t_measurements_i = np.array(t_measurements_i) / 24\n",
    "        \n",
    "        # plot dosing\n",
    "        for di, dose_time in enumerate(doses_time_points_i):\n",
    "            if di == 0:\n",
    "                dosing = ax[0, i].axvline(dose_time, color='black', linestyle='-', linewidth=0.5,\n",
    "                alpha=0.2, label='new dose')\n",
    "            else:\n",
    "                ax[0, i].axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "            ax[0, i].axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "            ax[1, i].axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "            ax[2, i].axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "            ax[3, i].axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "        \n",
    "        # plot median\n",
    "        ax[0, i].plot(t_measurement, np.median(simulations_i[:, :, 0], axis=0), color='blue',\n",
    "                      label='A2 simulated')\n",
    "        ax[2, i].plot(t_measurement, np.median(simulations_i[:, :, 1], axis=0), color='blue',\n",
    "                      label='A3 simulated')\n",
    "        ax[1, i].plot(t_measurement, np.median(simulations_nonmem_i[:, :, 0], axis=0), color='green',\n",
    "                      label='A2 FOCEI')\n",
    "        ax[3, i].plot(t_measurement, np.median(simulations_nonmem_i[:, :, 1], axis=0), color='green',\n",
    "                      label='A3 FOCEI')\n",
    "        \n",
    "        # plot 95% quantiles\n",
    "        ax[0, i].fill_between(t_measurement, np.quantile(simulations_i[:, :, 0], 0.025, axis=0), \n",
    "                              np.quantile(simulations_i[:, :, 0], 0.975, axis=0), \n",
    "                              color='blue', alpha=0.2)\n",
    "        ax[2, i].fill_between(t_measurement, np.quantile(simulations_i[:, :, 1], 0.025, axis=0), \n",
    "                              np.quantile(simulations_i[:, :, 0], 0.975, axis=0), \n",
    "                              color='blue', alpha=0.2)\n",
    "        ax[1, i].fill_between(t_measurement, np.quantile(simulations_nonmem_i[:, :, 0], 0.025, axis=0), \n",
    "                              np.quantile(simulations_nonmem_i[:, :, 0], 0.975, axis=0), \n",
    "                              color='green', alpha=0.2)\n",
    "        ax[3, i].fill_between(t_measurement, np.quantile(simulations_nonmem_i[:, :, 1], 0.025, axis=0), \n",
    "                              np.quantile(simulations_nonmem_i[:, :, 1], 0.975, axis=0), \n",
    "                              color='green', alpha=0.2)\n",
    "        \n",
    "            \n",
    "        a2 = ax[0, i].scatter(t_measurements_i, y_i[:, 0], marker='x', label='Sunitinib plasma', color='red')\n",
    "        a3 = ax[2, i].scatter(t_measurements_i, y_i[:, 1], marker='o', label='SU12662 plasma', color='red')\n",
    "        ax[1, i].scatter(t_measurements_i, y_i[:, 0], marker='x', label='Sunitinib plasma', color='red')\n",
    "        ax[3, i].scatter(t_measurements_i, y_i[:, 1], marker='o', label='SU12662 plasma', color='red')\n",
    "        #ax[i].scatter(t_measurements_i, y_i[:, 1], label='data', color='green')\n",
    "        ax[0, i].set_title(f'Individual {j}')\n",
    "        i += 1\n",
    "    \n",
    "    #for a in ax.flatten():\n",
    "    #    a.legend()\n",
    "    ax[1, 0].text(-0.2, 1.2, 'Sunitinib plasma', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax[1, 0].transAxes, rotation=90, fontsize=18)\n",
    "    ax[3, 0].text(-0.2, 1.2, 'SU12662 plasma', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax[3, 0].transAxes, rotation=90, fontsize=18)\n",
    "    ax[-1, 0].set_xlabel('Time (in days)')\n",
    "    ax[-1, 1].set_xlabel('Time (in days)')\n",
    "    ax[-1, 2].set_xlabel('Time (in days)')\n",
    "        \n",
    "    conf_int_patch = mpatches.Patch(color='grey', label='95\\% of population likelihood')\n",
    "    median_patch, = plt.plot([], [], color='black', label='median')\n",
    "    amortized = mpatches.Patch(color='blue', label='amortized approach')\n",
    "    focei = mpatches.Patch(color='green', label='baseline (FOCEI)')\n",
    "    lgd = fig.legend(handles=[conf_int_patch, median_patch, dosing, a2, a3, amortized, focei],\n",
    "            loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.12))\n",
    "    #plt.savefig('../plots/paper/pharma_model_simulations.pdf', format='pdf', bbox_inches='tight', pad_inches=0.2,\n",
    "    #            \n",
    "    #            bbox_extra_artists=(lgd,))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d05cb2f9ced5f7fd",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 20,\n",
    "                     'text.usetex': True,\n",
    "                     \"font.family\": \"serif\",\n",
    "                     \"font.serif\": [\"Computer Modern Roman\"],\n",
    "                     'axes.titlesize': 'small',\n",
    "                     'axes.labelsize': 'small',\n",
    "                     'xtick.labelsize': 'x-small',\n",
    "                     'ytick.labelsize': 'x-small',\n",
    "                     'legend.fontsize': 'small',\n",
    "                     #'figure.dpi': 600,\n",
    "                     'figure.figsize': (16,9)}) #"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d7ecda52086742a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if 'Pharmacokinetic' in individual_model.name:\n",
    "    # plot individuals with samples from the population parameters\n",
    "    #fig, ax = plt.subplots(2, 2, figsize=(7, 3), sharex='col', sharey='col', tight_layout=True)\n",
    "    # make grid plot, one col with one plot and one col with two plots\n",
    "    fig = plt.figure(figsize=(7, 3), tight_layout=True)\n",
    "    grid = plt.GridSpec(2, 2, figure=fig, hspace=0.2, wspace=0.35)\n",
    "    ax_0 = plt.subplot(grid[:, 1])\n",
    "    ax_00 = plt.subplot(grid[0, 0])\n",
    "    ax_01 = plt.subplot(grid[1, 0], sharey=ax_00)\n",
    "    \n",
    "    # plot random individuals\n",
    "    rand_indv = [17] #[0, 17, 33] #10\n",
    "    #rand_indv = np.random.choice(range(len(obs_data)), len(ax[0]))\n",
    "    i = 0\n",
    "    for j, (patient_i, simulations_i, simulations_nonmem_i) in enumerate(zip(obs_data, simulations_full, simulations_FOCEI_full)):\n",
    "        if j not in rand_indv:\n",
    "            continue\n",
    "        \n",
    "        y_i, t_measurements_i, doses_time_points, _, _ = convert_bf_to_observables(patient_i)\n",
    "        t_measurement = np.linspace(0, t_measurements_i[-1]*1.1, int(t_measurements_i[-1])) / 24\n",
    "        t_measurements_i = t_measurements_i / 24\n",
    "        doses_time_points = doses_time_points / 24\n",
    "        \n",
    "        # plot dosing\n",
    "        for di, dose_time in enumerate(doses_time_points):\n",
    "            if di == 0:\n",
    "                dosing = ax_00.axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2, label='new dose')\n",
    "            else:\n",
    "                #ax[0, 0].axvline(dose_time, color='black', linestyle='--', alpha=0.2)\n",
    "                ax_00.axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "            #ax[1, 0].axvline(dose_time, color='black', linestyle='--', alpha=0.2)\n",
    "            ax_01.axvline(dose_time, color='black', linestyle='-', linewidth=0.5, alpha=0.2)\n",
    "        \n",
    "        # plot 95% quantiles\n",
    "        ax_00.fill_between(t_measurement, np.quantile(simulations_i[:, :, 0], 0.025, axis=0), \n",
    "                              np.quantile(simulations_i[:, :, 0], 0.975, axis=0), \n",
    "                              color='blue', alpha=0.2)\n",
    "        #ax[0, 1].fill_between(t_measurement, np.quantile(simulations_i[:, :, 1], 0.025, axis=0), \n",
    "        #                      np.quantile(simulations_i[:, :, 0], 0.975, axis=0), \n",
    "        #                      color='green', alpha=0.2)\n",
    "        ax_01.fill_between(t_measurement, np.quantile(simulations_nonmem_i[:, :, 0], 0.025, axis=0), \n",
    "                              np.quantile(simulations_nonmem_i[:, :, 0], 0.975, axis=0), \n",
    "                              color='green', alpha=0.2)\n",
    "        #ax[1, 1].fill_between(t_measurement, np.quantile(simulations_nonmem_i[:, :, 1], 0.025, axis=0), \n",
    "        #                      np.quantile(simulations_nonmem_i[:, :, 1], 0.975, axis=0), \n",
    "        #                      color='green', alpha=0.2)\n",
    "        \n",
    "        # plot median\n",
    "        amortized, = ax_00.plot(t_measurement, np.median(simulations_i[:, :, 0], axis=0), color='blue',\n",
    "                      label='Amortized Approach')\n",
    "        #amortized2, = ax[0, 1].plot(t_measurement, np.median(simulations_i[:, :, 1], axis=0), color='green',\n",
    "        #              label='Amortized Approach')\n",
    "        focei, = ax_01.plot(t_measurement, np.median(simulations_nonmem_i[:, :, 0], axis=0), color='green',\n",
    "                      label='FOCEI')\n",
    "        #focei2, = ax[1, 1].plot(t_measurement, np.median(simulations_nonmem_i[:, :, 1], axis=0), color='green',\n",
    "        #              label='FOCEI')\n",
    "        \n",
    "        sunitinib = ax_00.scatter(t_measurements_i, y_i[:, 0], marker='x', label='measurements', color='red')\n",
    "                                  #label='Sunitinib plasma measurements', color='red')\n",
    "        #SU12662 = ax[0, 1].scatter(t_measurements_i, y_i[:, 1], label='SU12662 plasma measurements', color='green')\n",
    "        ax_01.scatter(t_measurements_i, y_i[:, 0],  marker='x', label='Sunitinib plasma measurements', color='red')\n",
    "        #ax[1, 1].scatter(t_measurements_i, y_i[:, 1], label='SU12662 plasma measurements', color='green')\n",
    "\n",
    "        ax_01.set_xlabel('Time (in days)')\n",
    "        ax_00.set_xticks(ax_01.get_xticks()[1:], labels=[])\n",
    "        #ax[1, 1].set_xlabel('Time (in days)')\n",
    "        #ax_01.set_ylabel('$\\qquad \\qquad \\qquad \\qquad$ Measurements')\n",
    "        #ax_01.set_ylabel('Measurements')\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    \n",
    "    ax_0.scatter(sim_a2_FOCEI, real_data_a2, marker='o', color='green', alpha=0.5, label='FOCEI')\n",
    "    ax_0.scatter(sim_a2_SAEM, real_data_a2, marker='o', color='orange', label='SAEM')\n",
    "    ax_0.scatter(sim_a2, real_data_a2, marker='o', color='blue', alpha=0.5, label='Amortized')\n",
    "\n",
    "    ax_0.plot(real_data_a2, real_data_a2, color='red', linestyle='--')\n",
    "    #ax_0.set_title('Q-Q Plot - A2')\n",
    "    ax_00.text(-0.25, -0.1, 'Log-Measurements', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax_00.transAxes, rotation=90, fontsize=18)\n",
    "    ax_00.text(0.75, 0.1, '91\\% covered', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax_00.transAxes, fontsize=15)\n",
    "    ax_01.text(0.75, 0.1, '36\\% covered', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax_01.transAxes, fontsize=15)\n",
    "    \n",
    "    ax_0.set_xlabel('Simulations')\n",
    "    ax_0.set_ylim(-5, 5)\n",
    "    ax_0.set_xlim(-5, 5)\n",
    "    ax_0.set_yticks([-5, -2.5, 0, 2.5, 5])\n",
    "    ax_0.set_xticks([-5, -2.5, 0, 2.5, 5])\n",
    "    ax_0.set_aspect('equal')\n",
    "\n",
    "    \n",
    "    #ax[0, 1].legend(handles=[amortized], loc='lower left')\n",
    "    #ax[0, 1].legend(handles=[amortized2], loc='lower left')\n",
    "    #ax[1, 1].legend(handles=[focei], loc='lower left')\n",
    "    #ax[1, 1].legend(handles=[focei2], loc='lower left')\n",
    "\n",
    "    conf_int_patch = mpatches.Patch(color='grey', label='95\\% of simulations')\n",
    "    amortized = mpatches.Patch(color='blue', label='amortized')\n",
    "    focei = mpatches.Patch(color='green', label='FOCEI')\n",
    "    saem = mpatches.Patch(color='orange', label='SAEM')\n",
    "    median_patch, = plt.plot([], [], color='black', label='median')\n",
    "    #lgd = fig.legend(handles=[sunitinib, SU12662, dosing, conf_int_patch, median_patch],\n",
    "    #        loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.15))\n",
    "    lgd = fig.legend(handles=[conf_int_patch, sunitinib, median_patch, dosing, focei, saem, amortized],\n",
    "            loc='lower center', ncol=4, bbox_to_anchor=(0.46, -0.31), prop={'size': 12})\n",
    "    ax_0.text(-0.25, 1, '\\\\bf{B}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax_0.transAxes, fontsize=20)\n",
    "    ax_00.text(-0.25, 1, '\\\\bf{A}', horizontalalignment='center', verticalalignment='center',\n",
    "         transform=ax_00.transAxes, fontsize=20)\n",
    "    \n",
    "    plt.savefig('../plots/paper/pharma_model_simulations_qqplot.pdf', format='pdf', bbox_inches='tight', pad_inches=0.15,\n",
    "                \n",
    "                bbox_extra_artists=(lgd,))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16415ce78d3fcb44",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " if 'Pharmacokinetic' in individual_model.name:\n",
    "    in_95_quantile = []\n",
    "    in_95_quantile_nonmem = []\n",
    "    in_99_quantile = []\n",
    "    in_99_quantile_nonmem = []\n",
    "    in_80_quantile = []\n",
    "    in_80_quantile_nonmem = []\n",
    "    for i, (patient_i, simulations_i, simulations_nonmem_i) in enumerate(zip(obs_data, simulations, simulations_FOCEI)):\n",
    "        y_i, t_measurements_i, _, _, _ = convert_bf_to_observables(patient_i)\n",
    "        t_measurement = np.linspace(0, t_measurements_i[-1]*1.1, int(t_measurements_i[-1]))\n",
    "        \n",
    "        # compute how many measurements are in the 80% quantile\n",
    "        sim_quantiles = np.quantile(simulations_i[:, :, 0], [0.1, 0.9], axis=0)\n",
    "        sim_quantiles_nonmem = np.quantile(simulations_nonmem_i[:, :, 0], [0.1, 0.9], axis=0)\n",
    "        in_80_quantile.append(np.logical_and(y_i[:, 0] > sim_quantiles[0],\n",
    "                                             y_i[:, 0] < sim_quantiles[1]))\n",
    "        in_80_quantile_nonmem.append(np.logical_and(y_i[:, 0] > sim_quantiles_nonmem[0],\n",
    "                                                    y_i[:, 0] < sim_quantiles_nonmem[1]))\n",
    "        sim_quantiles = np.quantile(simulations_i[:, :, 1], [0.1, 0.9], axis=0)\n",
    "        sim_quantiles_nonmem = np.quantile(simulations_nonmem_i[:, :, 1], [0.1, 0.9], axis=0)\n",
    "        in_80_quantile.append(np.logical_and(y_i[:, 1] > sim_quantiles[0],\n",
    "                                             y_i[:, 1] < sim_quantiles[1]))\n",
    "        in_80_quantile_nonmem.append(np.logical_and(y_i[:, 1] > sim_quantiles_nonmem[0],\n",
    "                                                    y_i[:, 1] < sim_quantiles_nonmem[1]))\n",
    "        \n",
    "        # compute how many measurements are in the 95% quantile\n",
    "        sim_quantiles = np.quantile(simulations_i[:, :, 0], [0.025, 0.975], axis=0)\n",
    "        sim_quantiles_nonmem = np.quantile(simulations_nonmem_i[:, :, 0], [0.025, 0.975], axis=0)\n",
    "        in_95_quantile.append(np.logical_and(y_i[:, 0] > sim_quantiles[0],\n",
    "                                             y_i[:, 0] < sim_quantiles[1]))\n",
    "        in_95_quantile_nonmem.append(np.logical_and(y_i[:, 0] > sim_quantiles_nonmem[0],\n",
    "                                                    y_i[:, 0] < sim_quantiles_nonmem[1]))\n",
    "        sim_quantiles = np.quantile(simulations_i[:, :, 1], [0.025, 0.975], axis=0)\n",
    "        sim_quantiles_nonmem = np.quantile(simulations_nonmem_i[:, :, 1], [0.025, 0.975], axis=0)\n",
    "        in_95_quantile.append(np.logical_and(y_i[:, 1] > sim_quantiles[0],\n",
    "                                             y_i[:, 1] < sim_quantiles[1]))\n",
    "        in_95_quantile_nonmem.append(np.logical_and(y_i[:, 1] > sim_quantiles_nonmem[0],\n",
    "                                                    y_i[:, 1] < sim_quantiles_nonmem[1]))\n",
    "        \n",
    "        # compute how many measurements are in the 99% quantile\n",
    "        sim_quantiles = np.quantile(simulations_i[:, :, 0], [0.005, 0.995], axis=0)\n",
    "        sim_quantiles_nonmem = np.quantile(simulations_nonmem_i[:, :, 0], [0.005, 0.995], axis=0)\n",
    "        in_99_quantile.append(np.logical_and(y_i[:, 0] > sim_quantiles[0],\n",
    "                                             y_i[:, 0] < sim_quantiles[1]))\n",
    "        in_99_quantile_nonmem.append(np.logical_and(y_i[:, 0] > sim_quantiles_nonmem[0],\n",
    "                                                    y_i[:, 0] < sim_quantiles_nonmem[1]))\n",
    "        sim_quantiles = np.quantile(simulations_i[:, :, 1], [0.005, 0.995], axis=0)\n",
    "        sim_quantiles_nonmem = np.quantile(simulations_nonmem_i[:, :, 1], [0.005, 0.995], axis=0)\n",
    "        in_99_quantile.append(np.logical_and(y_i[:, 1] > sim_quantiles[0],\n",
    "                                             y_i[:, 1] < sim_quantiles[1]))\n",
    "        in_99_quantile_nonmem.append(np.logical_and(y_i[:, 1] > sim_quantiles_nonmem[0],\n",
    "                                                    y_i[:, 1] < sim_quantiles_nonmem[1]))\n",
    "        \n",
    "in_95_quantile = np.concatenate(in_95_quantile)\n",
    "in_95_quantile_nonmem = np.concatenate(in_95_quantile_nonmem)\n",
    "in_99_quantile = np.concatenate(in_99_quantile)\n",
    "in_99_quantile_nonmem = np.concatenate(in_99_quantile_nonmem)\n",
    "in_80_quantile = np.concatenate(in_80_quantile)\n",
    "in_80_quantile_nonmem = np.concatenate(in_80_quantile_nonmem)\n",
    "print(f'In total {np.sum(in_80_quantile)/len(in_80_quantile)} measurements are in the 80% quantile')\n",
    "print(f'In total {np.sum(in_80_quantile_nonmem)/len(in_80_quantile_nonmem)} measurements are in the 80% quantile')\n",
    "print(f'In total {np.sum(in_95_quantile)/len(in_95_quantile)} measurements are in the 95% quantile')\n",
    "print(f'In total {np.sum(in_95_quantile_nonmem)/len(in_95_quantile_nonmem)} measurements are in the 95% quantile')\n",
    "print(f'In total {np.sum(in_99_quantile)/len(in_99_quantile)} measurements are in the 99% quantile')\n",
    "print(f'In total {np.sum(in_99_quantile_nonmem)/len(in_99_quantile_nonmem)} measurements are in the 99% quantile')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445f33016bc551cb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "raw_data['computation_time'].sum()/60/60, 9.83+11.25+(1/60+43/60/60)*200+(505/60/60)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cf42a44d07d9242",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "da70f2e8",
   "metadata": {},
   "source": [
    "# Uncertainty Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a186fb11",
   "metadata": {},
   "source": [
    "Uncertainty based on profiles -> more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_options = profile.ProfileOptions(\n",
    "    #min_step_size=0.0001, #0.001\n",
    "    #step_size_factor=1.25, #1.25\n",
    "    delta_ratio_max=0.01, #0.1\n",
    "    #default_step_size=0.0001, #0.01\n",
    "    #ratio_min=0.145 #0.145\n",
    ")\n",
    "\n",
    "pypesto_result = profile.parameter_profile(\n",
    "    problem=pypesto_result.problem,\n",
    "    result=pypesto_result,\n",
    "    optimizer=optimize.ScipyOptimizer(), #(options={'disp': True}),\n",
    "    engine=engine.MultiProcessEngine(10),\n",
    "    #profile_options=profile_options,\n",
    "    #filename=f'../Experiments/synthetic_results_amortized/uncertainty_{individual_model.name}_cells_{n_data}_samples_{100}.hd5',\n",
    "    #overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(pypesto_result, size=(16,12), \n",
    "                   profile_list_ids=list(np.arange(len(pypesto_result.profile_result.list)))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = visualize.profile_cis(pypesto_result, profile_list=len(pypesto_result.profile_result.list)-1)\n",
    "#ax.set_title('Approximate Confidence Intervals \\n Based on Profiles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac88c2",
   "metadata": {},
   "source": [
    "Uncertainty based on FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pypesto_result = profile.approximate_parameter_profile(\n",
    "    problem=pypesto_result.problem,\n",
    "    result=pypesto_result,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.profiles(pypesto_result, \n",
    "                   profile_list_ids=list(np.arange(len(pypesto_result.profile_result.list)))\n",
    "                   )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = visualize.profile_cis(pypesto_result, profile_list=len(pypesto_result.profile_result.list)-1)\n",
    "ax.set_title('Approximate Confidence Intervals \\n Based on Profiles')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8d4fffc09c3b1cf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pypesto import store\n",
    "\n",
    "store.write_result(pypesto_result, \n",
    "                   f'../Experiments/synthetic_results_amortized/uncertainty_{model_name}_cells_500_samples_100.hdf5')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65ac907dd6a1f312",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f54af7d4a4b98fab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
